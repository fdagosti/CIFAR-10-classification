{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/cifar/cifar-10-python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 3:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 994, 1: 1042, 2: 965, 3: 997, 4: 990, 5: 1029, 6: 978, 7: 1015, 8: 961, 9: 1029}\n",
      "First 20 Labels: [8, 5, 0, 6, 9, 2, 8, 3, 6, 2, 7, 4, 6, 9, 0, 0, 7, 3, 7, 2]\n",
      "\n",
      "Example of Image 2017:\n",
      "Image - Min Value: 0 Max Value: 255\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 9 Name: truck\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f05d682c3c8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 3\n",
    "sample_id = 2017\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return x/255\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "encodings_map = preprocessing.LabelBinarizer()\n",
    "encodings_map.fit(list(range(10)))\n",
    "\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return encodings_map.transform(x)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, [None, image_shape[0],image_shape[1],image_shape[2]], name=\"x\")\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, [None, n_classes], name=\"y\")\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement Function\n",
    "    shape = [conv_ksize[0], conv_ksize[1], x_tensor.shape[3].value, conv_num_outputs]\n",
    "    weight = tf.Variable(tf.random_normal(shape))\n",
    "\n",
    "    bias = tf.Variable(tf.random_normal([conv_num_outputs]))\n",
    "\n",
    "    conv_layer = tf.nn.conv2d(x_tensor, weight, [1, conv_strides[0], conv_strides[1], 1], padding=\"SAME\")\n",
    "    conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "    conv_layer = tf.nn.max_pool(conv_layer, [1, pool_ksize[0], pool_ksize[1], 1] , [1, pool_strides[0], pool_strides[1], 1], padding=\"SAME\")\n",
    "    return conv_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    input_shape = x_tensor.shape\n",
    "    image_reshape = input_shape[1]*input_shape[2]*input_shape[3]\n",
    "    # print(\"image reshape \",x_tensor.get_shape().as_list()[1:])\n",
    "    return tf.reshape(x_tensor, [-1, image_reshape.value])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weight = tf.Variable(tf.random_normal([x_tensor.shape[1].value, num_outputs]))\n",
    "    bias = tf.Variable(tf.random_normal([num_outputs]))\n",
    "#    fc1 = tf.reshape(x_tensor, [-1, ])\n",
    "    fc1 = tf.add(tf.matmul(x_tensor, weight), bias)\n",
    "    # print(\"full connected layer \",x_tensor.shape)\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    return fc1\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weight = tf.Variable(tf.random_normal([x_tensor.shape[1].value, num_outputs]))\n",
    "    bias = tf.Variable(tf.random_normal([num_outputs]))\n",
    "    return tf.add(tf.matmul(x_tensor, weight), bias)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv1 = conv2d_maxpool(x, 64, [5, 5], [1,1], [3,3], [2,2])\n",
    "    conv2 = conv2d_maxpool(conv1, 64, [5, 5], [1,1], [3,3], [2,2])\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    flat = flatten(conv2)\n",
    "    \n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    fc1 = fully_conn(flat, 384)\n",
    "    fc2 = fully_conn(fc1, 192)\n",
    "    # fc2 = tf.nn.dropout(fc2, keep_prob)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    out = output(fc2, 10)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return out\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={\n",
    "            x: feature_batch,\n",
    "            y: label_batch,\n",
    "            keep_prob: keep_probability\n",
    "        })\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict={\n",
    "            x: feature_batch,\n",
    "            y:label_batch,\n",
    "            keep_prob: 1\n",
    "        })\n",
    "    valid_acc = session.run(accuracy, feed_dict={\n",
    "            x: valid_features,\n",
    "            y: valid_labels,\n",
    "            keep_prob: 1\n",
    "        })\n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss,valid_acc))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 100\n",
    "batch_size = 512\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss: 286897.3438 Validation Accuracy: 0.168200\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss: 209646.3125 Validation Accuracy: 0.212600\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss: 164576.3125 Validation Accuracy: 0.231400\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss: 136826.4375 Validation Accuracy: 0.243800\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss: 117573.0469 Validation Accuracy: 0.253200\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss: 103032.0078 Validation Accuracy: 0.265200\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss: 92371.2812 Validation Accuracy: 0.272200\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss: 83404.1094 Validation Accuracy: 0.276400\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss: 76112.4141 Validation Accuracy: 0.283800\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss: 71191.9922 Validation Accuracy: 0.292000\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss: 65549.0000 Validation Accuracy: 0.292400\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss: 60886.4922 Validation Accuracy: 0.301800\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss: 56186.1055 Validation Accuracy: 0.306200\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss: 52531.9883 Validation Accuracy: 0.313800\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss: 50171.3984 Validation Accuracy: 0.323800\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss: 48250.8477 Validation Accuracy: 0.327400\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss: 49467.8867 Validation Accuracy: 0.323000\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss: 43942.3438 Validation Accuracy: 0.333000\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss: 39826.3398 Validation Accuracy: 0.340800\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss: 37348.5312 Validation Accuracy: 0.341000\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss: 35579.3047 Validation Accuracy: 0.338400\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss: 34617.5977 Validation Accuracy: 0.330600\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss: 33663.1836 Validation Accuracy: 0.334200\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss: 31384.4512 Validation Accuracy: 0.337600\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss: 30618.2812 Validation Accuracy: 0.330400\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss: 30978.3164 Validation Accuracy: 0.333600\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss: 30613.1758 Validation Accuracy: 0.330000\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss: 26411.9668 Validation Accuracy: 0.347200\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss: 24191.5371 Validation Accuracy: 0.358200\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss: 23351.6367 Validation Accuracy: 0.363200\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss: 21880.3828 Validation Accuracy: 0.364000\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss: 21193.6445 Validation Accuracy: 0.367600\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss: 22235.4277 Validation Accuracy: 0.358600\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss: 20272.1328 Validation Accuracy: 0.364600\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss: 19576.5801 Validation Accuracy: 0.365600\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss: 18205.0859 Validation Accuracy: 0.371600\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss: 16737.3203 Validation Accuracy: 0.374200\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss: 16195.2637 Validation Accuracy: 0.377800\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss: 17015.5156 Validation Accuracy: 0.372000\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss: 15796.6094 Validation Accuracy: 0.372200\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss: 14832.5918 Validation Accuracy: 0.371600\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss: 14212.1885 Validation Accuracy: 0.379600\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss: 15732.9160 Validation Accuracy: 0.367400\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss: 14718.0723 Validation Accuracy: 0.368800\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss: 13134.7178 Validation Accuracy: 0.370000\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss: 13082.5156 Validation Accuracy: 0.373800\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss: 11812.3809 Validation Accuracy: 0.382800\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss: 12146.8164 Validation Accuracy: 0.376600\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss: 12130.8340 Validation Accuracy: 0.379000\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss: 10966.6709 Validation Accuracy: 0.383000\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss: 10448.9600 Validation Accuracy: 0.385000\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss: 11609.1475 Validation Accuracy: 0.381400\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss: 11354.0889 Validation Accuracy: 0.380800\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:  9721.7998 Validation Accuracy: 0.384200\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:  8798.0723 Validation Accuracy: 0.384800\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:  8035.9688 Validation Accuracy: 0.391000\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:  7182.0410 Validation Accuracy: 0.391600\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:  6819.4556 Validation Accuracy: 0.390200\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:  6731.2617 Validation Accuracy: 0.391600\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:  7017.0967 Validation Accuracy: 0.391600\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:  7433.1904 Validation Accuracy: 0.393400\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:  7017.2222 Validation Accuracy: 0.392600\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:  6873.7881 Validation Accuracy: 0.387600\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:  7221.3818 Validation Accuracy: 0.386800\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:  5421.8477 Validation Accuracy: 0.394000\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:  5897.1885 Validation Accuracy: 0.390400\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:  6287.3887 Validation Accuracy: 0.387600\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:  5354.3926 Validation Accuracy: 0.393800\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:  4624.2754 Validation Accuracy: 0.397600\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:  5396.7490 Validation Accuracy: 0.393600\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:  6000.6616 Validation Accuracy: 0.387800\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:  5193.6860 Validation Accuracy: 0.395800\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:  8088.0654 Validation Accuracy: 0.379600\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:  5713.9248 Validation Accuracy: 0.387600\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:  4797.0049 Validation Accuracy: 0.396800\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:  4488.6562 Validation Accuracy: 0.399000\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:  4574.6250 Validation Accuracy: 0.401600\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:  3969.6809 Validation Accuracy: 0.400400\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:  3330.5586 Validation Accuracy: 0.399600\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:  3334.8179 Validation Accuracy: 0.398800\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:  3561.8071 Validation Accuracy: 0.400000\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:  3698.2319 Validation Accuracy: 0.405200\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:  3759.3855 Validation Accuracy: 0.408400\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:  4124.5903 Validation Accuracy: 0.402200\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:  4566.8950 Validation Accuracy: 0.396200\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:  3830.2246 Validation Accuracy: 0.396800\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:  4404.6611 Validation Accuracy: 0.400800\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:  4854.1514 Validation Accuracy: 0.391800\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:  4855.4404 Validation Accuracy: 0.392200\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:  3074.1257 Validation Accuracy: 0.403200\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:  2165.2412 Validation Accuracy: 0.404800\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:  1800.8075 Validation Accuracy: 0.407200\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:  2019.1876 Validation Accuracy: 0.405800\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:  1824.7438 Validation Accuracy: 0.406600\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:  1521.2056 Validation Accuracy: 0.409800\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:  1705.3455 Validation Accuracy: 0.414000\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:  1524.6365 Validation Accuracy: 0.406600\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:  1504.8054 Validation Accuracy: 0.410000\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:  1543.0201 Validation Accuracy: 0.406200\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:  1606.6111 Validation Accuracy: 0.400800\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss: 262858.9062 Validation Accuracy: 0.160200\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss: 167779.7812 Validation Accuracy: 0.214000\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss: 144247.1562 Validation Accuracy: 0.227600\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss: 119414.0703 Validation Accuracy: 0.241400\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss: 102721.4688 Validation Accuracy: 0.258000\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss: 103969.6875 Validation Accuracy: 0.268200\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss: 85918.2031 Validation Accuracy: 0.278800\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss: 78864.7656 Validation Accuracy: 0.281600\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss: 77035.3906 Validation Accuracy: 0.291800\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss: 67390.7656 Validation Accuracy: 0.294400\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss: 73560.7656 Validation Accuracy: 0.301400\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss: 58150.5938 Validation Accuracy: 0.302000\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss: 57792.2344 Validation Accuracy: 0.306400\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss: 56596.3789 Validation Accuracy: 0.311600\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss: 51776.1289 Validation Accuracy: 0.317600\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss: 56428.1211 Validation Accuracy: 0.323800\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss: 46733.1875 Validation Accuracy: 0.328600\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss: 46636.5312 Validation Accuracy: 0.325800\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss: 43722.5078 Validation Accuracy: 0.334200\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss: 42620.2930 Validation Accuracy: 0.337800\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss: 47055.8281 Validation Accuracy: 0.340200\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss: 40126.8359 Validation Accuracy: 0.347000\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss: 38630.5547 Validation Accuracy: 0.350000\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss: 35312.8867 Validation Accuracy: 0.346000\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss: 36954.8984 Validation Accuracy: 0.345000\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss: 40080.1406 Validation Accuracy: 0.355000\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss: 35116.5352 Validation Accuracy: 0.348400\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss: 33290.6094 Validation Accuracy: 0.349200\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss: 29886.0996 Validation Accuracy: 0.354400\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss: 33007.0391 Validation Accuracy: 0.354600\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss: 36025.3047 Validation Accuracy: 0.359000\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss: 31471.3086 Validation Accuracy: 0.363000\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss: 30116.4805 Validation Accuracy: 0.364600\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss: 25857.4883 Validation Accuracy: 0.367000\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss: 29219.1152 Validation Accuracy: 0.362000\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss: 30757.4883 Validation Accuracy: 0.369000\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss: 28327.5781 Validation Accuracy: 0.367200\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss: 26660.1875 Validation Accuracy: 0.371600\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss: 22812.9160 Validation Accuracy: 0.372000\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss: 26203.6426 Validation Accuracy: 0.371200\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss: 27813.2305 Validation Accuracy: 0.379000\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss: 25175.3672 Validation Accuracy: 0.377800\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss: 23523.6836 Validation Accuracy: 0.376800\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss: 20201.9590 Validation Accuracy: 0.375600\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss: 23450.3027 Validation Accuracy: 0.380200\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss: 25258.9355 Validation Accuracy: 0.381800\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss: 22272.2500 Validation Accuracy: 0.387200\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss: 21409.7715 Validation Accuracy: 0.380800\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss: 17684.4297 Validation Accuracy: 0.379800\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss: 21524.7930 Validation Accuracy: 0.381400\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss: 23034.9863 Validation Accuracy: 0.382600\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss: 20035.1699 Validation Accuracy: 0.385600\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss: 19455.0645 Validation Accuracy: 0.383800\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss: 15603.4004 Validation Accuracy: 0.382600\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss: 19083.4082 Validation Accuracy: 0.382400\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss: 20588.0781 Validation Accuracy: 0.389800\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss: 17883.4434 Validation Accuracy: 0.393200\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss: 17907.9043 Validation Accuracy: 0.388200\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss: 13683.9590 Validation Accuracy: 0.386400\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss: 17303.9492 Validation Accuracy: 0.386400\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss: 18962.1035 Validation Accuracy: 0.389800\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss: 16796.1484 Validation Accuracy: 0.395400\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss: 16125.2344 Validation Accuracy: 0.397400\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss: 12409.3828 Validation Accuracy: 0.400000\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss: 15741.2871 Validation Accuracy: 0.395800\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss: 17323.9395 Validation Accuracy: 0.393400\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss: 15447.5566 Validation Accuracy: 0.402200\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss: 14631.7461 Validation Accuracy: 0.402200\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss: 11421.7910 Validation Accuracy: 0.409000\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss: 14231.6289 Validation Accuracy: 0.404400\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss: 16213.2676 Validation Accuracy: 0.404800\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss: 14251.2432 Validation Accuracy: 0.404400\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss: 13359.4717 Validation Accuracy: 0.409800\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss: 10540.1523 Validation Accuracy: 0.410200\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss: 13115.2656 Validation Accuracy: 0.412600\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss: 15060.1729 Validation Accuracy: 0.409000\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss: 13085.4727 Validation Accuracy: 0.404400\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss: 12016.7520 Validation Accuracy: 0.409600\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:  9760.1631 Validation Accuracy: 0.412000\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss: 11950.0254 Validation Accuracy: 0.413200\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss: 13813.3398 Validation Accuracy: 0.409800\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss: 11924.5898 Validation Accuracy: 0.410400\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss: 11033.1816 Validation Accuracy: 0.412000\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:  9074.8652 Validation Accuracy: 0.414200\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss: 11095.5547 Validation Accuracy: 0.420200\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss: 12755.5928 Validation Accuracy: 0.413800\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss: 10940.1221 Validation Accuracy: 0.408200\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss: 10204.5830 Validation Accuracy: 0.419400\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:  8553.8896 Validation Accuracy: 0.417800\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss: 10398.0703 Validation Accuracy: 0.422800\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss: 11716.8623 Validation Accuracy: 0.419600\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss: 10223.1475 Validation Accuracy: 0.412000\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:  9354.6895 Validation Accuracy: 0.419800\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:  7825.2383 Validation Accuracy: 0.421600\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:  9882.9375 Validation Accuracy: 0.429800\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss: 10898.4561 Validation Accuracy: 0.422200\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:  9517.4902 Validation Accuracy: 0.418200\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:  8595.4297 Validation Accuracy: 0.418200\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:  7285.5107 Validation Accuracy: 0.427000\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:  9194.0654 Validation Accuracy: 0.427800\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss: 10166.1416 Validation Accuracy: 0.423200\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:  8868.1982 Validation Accuracy: 0.426400\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:  8164.7520 Validation Accuracy: 0.424600\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:  6940.6538 Validation Accuracy: 0.428000\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:  8666.9922 Validation Accuracy: 0.433600\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:  9718.8516 Validation Accuracy: 0.423800\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:  8230.8691 Validation Accuracy: 0.429000\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss:  7733.3672 Validation Accuracy: 0.426400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, CIFAR-10 Batch 4:  Loss:  6413.7090 Validation Accuracy: 0.430200\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:  8361.7344 Validation Accuracy: 0.437400\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:  9059.5615 Validation Accuracy: 0.431400\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss:  7762.1309 Validation Accuracy: 0.428400\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:  7247.8828 Validation Accuracy: 0.427800\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:  6040.9717 Validation Accuracy: 0.436400\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:  7756.0181 Validation Accuracy: 0.440400\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:  8616.9570 Validation Accuracy: 0.428600\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:  7358.8193 Validation Accuracy: 0.432000\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:  6729.6523 Validation Accuracy: 0.429800\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:  5740.4717 Validation Accuracy: 0.437800\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:  7193.2285 Validation Accuracy: 0.440600\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:  8119.0249 Validation Accuracy: 0.427800\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:  6947.2900 Validation Accuracy: 0.433000\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:  6253.9937 Validation Accuracy: 0.431200\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:  5623.9839 Validation Accuracy: 0.441400\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:  6614.0884 Validation Accuracy: 0.439800\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:  7542.8418 Validation Accuracy: 0.440800\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:  6542.9883 Validation Accuracy: 0.436600\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:  5907.3760 Validation Accuracy: 0.431800\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:  5383.9395 Validation Accuracy: 0.440800\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:  6374.1123 Validation Accuracy: 0.441000\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:  6920.7119 Validation Accuracy: 0.449400\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:  6185.3247 Validation Accuracy: 0.438600\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:  5381.0811 Validation Accuracy: 0.443000\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:  5170.2119 Validation Accuracy: 0.441200\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:  5826.3252 Validation Accuracy: 0.440600\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:  6511.0278 Validation Accuracy: 0.452600\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:  5792.7847 Validation Accuracy: 0.439800\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:  5302.5596 Validation Accuracy: 0.440600\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:  4909.5259 Validation Accuracy: 0.436800\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:  5862.2998 Validation Accuracy: 0.438800\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:  6143.2710 Validation Accuracy: 0.454800\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:  5348.2705 Validation Accuracy: 0.446400\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:  4775.6357 Validation Accuracy: 0.444800\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:  4801.4429 Validation Accuracy: 0.433800\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:  5594.7007 Validation Accuracy: 0.442000\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:  6059.2573 Validation Accuracy: 0.453000\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:  4953.3965 Validation Accuracy: 0.450800\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:  4451.7554 Validation Accuracy: 0.446000\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:  4715.2031 Validation Accuracy: 0.430400\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:  5107.3569 Validation Accuracy: 0.444000\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:  5883.4702 Validation Accuracy: 0.449800\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss:  4920.9658 Validation Accuracy: 0.455600\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss:  4273.6123 Validation Accuracy: 0.451800\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss:  4452.7236 Validation Accuracy: 0.435200\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss:  4656.1396 Validation Accuracy: 0.450800\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:  5422.9712 Validation Accuracy: 0.452400\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss:  4830.2427 Validation Accuracy: 0.455400\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss:  3982.5432 Validation Accuracy: 0.453600\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss:  4174.3105 Validation Accuracy: 0.436000\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss:  4378.4141 Validation Accuracy: 0.454200\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:  5099.7832 Validation Accuracy: 0.454000\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss:  4522.5718 Validation Accuracy: 0.454400\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss:  3730.3450 Validation Accuracy: 0.451800\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss:  3793.8201 Validation Accuracy: 0.446400\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss:  4154.7363 Validation Accuracy: 0.454000\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:  5064.1074 Validation Accuracy: 0.455000\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss:  4074.2207 Validation Accuracy: 0.458800\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss:  3289.1292 Validation Accuracy: 0.457600\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss:  3671.6716 Validation Accuracy: 0.448600\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss:  3712.3652 Validation Accuracy: 0.456200\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:  4671.6650 Validation Accuracy: 0.458800\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss:  3771.6572 Validation Accuracy: 0.458400\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss:  3266.0317 Validation Accuracy: 0.459600\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss:  3595.8909 Validation Accuracy: 0.452200\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss:  3639.7600 Validation Accuracy: 0.454200\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:  4411.8999 Validation Accuracy: 0.460000\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss:  3362.2283 Validation Accuracy: 0.460400\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss:  3012.5552 Validation Accuracy: 0.459800\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss:  3354.7034 Validation Accuracy: 0.455400\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss:  3692.8604 Validation Accuracy: 0.452000\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:  4062.4238 Validation Accuracy: 0.463400\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss:  3238.2708 Validation Accuracy: 0.456400\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss:  2823.8474 Validation Accuracy: 0.461000\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss:  3146.6228 Validation Accuracy: 0.457400\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss:  3529.4443 Validation Accuracy: 0.449600\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:  3932.7900 Validation Accuracy: 0.456200\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss:  3227.7432 Validation Accuracy: 0.446200\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss:  2859.5752 Validation Accuracy: 0.461000\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss:  3020.3240 Validation Accuracy: 0.455400\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss:  3240.5657 Validation Accuracy: 0.450800\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:  3767.2527 Validation Accuracy: 0.458200\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss:  2951.9819 Validation Accuracy: 0.448000\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss:  2677.4172 Validation Accuracy: 0.460800\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss:  2909.0249 Validation Accuracy: 0.452800\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss:  2893.8625 Validation Accuracy: 0.458600\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:  3503.2651 Validation Accuracy: 0.458400\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss:  2727.9194 Validation Accuracy: 0.460400\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss:  2525.0349 Validation Accuracy: 0.457400\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss:  2692.9502 Validation Accuracy: 0.454400\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss:  2742.2202 Validation Accuracy: 0.466400\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:  3324.8105 Validation Accuracy: 0.461800\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss:  2419.0200 Validation Accuracy: 0.467600\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss:  2393.7188 Validation Accuracy: 0.458600\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss:  2746.3538 Validation Accuracy: 0.456800\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss:  2624.9548 Validation Accuracy: 0.461200\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:  3083.1111 Validation Accuracy: 0.466400\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss:  2228.5193 Validation Accuracy: 0.472400\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss:  2268.2278 Validation Accuracy: 0.458600\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss:  2677.9897 Validation Accuracy: 0.460800\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss:  2389.7747 Validation Accuracy: 0.466800\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:  2996.8584 Validation Accuracy: 0.469600\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss:  2063.1165 Validation Accuracy: 0.471200\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss:  2104.8884 Validation Accuracy: 0.456600\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss:  2529.1428 Validation Accuracy: 0.460800\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss:  2200.1641 Validation Accuracy: 0.474800\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:  2667.2083 Validation Accuracy: 0.474400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, CIFAR-10 Batch 2:  Loss:  2030.2803 Validation Accuracy: 0.468800\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss:  1932.5052 Validation Accuracy: 0.457800\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss:  2439.0518 Validation Accuracy: 0.461600\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss:  2275.4922 Validation Accuracy: 0.464200\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:  2624.3694 Validation Accuracy: 0.475200\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss:  1876.7686 Validation Accuracy: 0.468400\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss:  1663.5950 Validation Accuracy: 0.465000\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss:  2283.5068 Validation Accuracy: 0.463400\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss:  2338.9575 Validation Accuracy: 0.455200\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:  2699.2085 Validation Accuracy: 0.471600\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss:  1700.5105 Validation Accuracy: 0.479600\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss:  1461.2084 Validation Accuracy: 0.472200\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss:  2259.8281 Validation Accuracy: 0.465200\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss:  2291.1323 Validation Accuracy: 0.452800\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:  2547.0237 Validation Accuracy: 0.475200\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss:  1804.6938 Validation Accuracy: 0.480000\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss:  1555.1991 Validation Accuracy: 0.470600\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss:  2144.6475 Validation Accuracy: 0.468000\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss:  1898.4104 Validation Accuracy: 0.461000\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:  2240.9036 Validation Accuracy: 0.474400\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss:  1911.6434 Validation Accuracy: 0.475800\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss:  1403.1697 Validation Accuracy: 0.466000\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss:  1886.8586 Validation Accuracy: 0.468600\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss:  1721.8406 Validation Accuracy: 0.466400\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:  2117.5049 Validation Accuracy: 0.470000\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss:  1832.7527 Validation Accuracy: 0.482000\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss:  1331.1208 Validation Accuracy: 0.469800\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss:  1803.6206 Validation Accuracy: 0.471400\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss:  1563.5544 Validation Accuracy: 0.470000\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:  2044.4116 Validation Accuracy: 0.472200\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss:  1693.3445 Validation Accuracy: 0.478600\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss:  1298.2894 Validation Accuracy: 0.461400\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss:  1711.9727 Validation Accuracy: 0.466200\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss:  1523.2771 Validation Accuracy: 0.468000\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:  1796.4451 Validation Accuracy: 0.475400\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss:  1532.4019 Validation Accuracy: 0.477800\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss:  1276.3718 Validation Accuracy: 0.457600\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss:  1574.4292 Validation Accuracy: 0.465000\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss:  1440.0063 Validation Accuracy: 0.464000\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:  1592.8323 Validation Accuracy: 0.481200\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss:  1382.1161 Validation Accuracy: 0.477800\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss:  1222.3391 Validation Accuracy: 0.463800\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss:  1623.3840 Validation Accuracy: 0.461200\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss:  1463.3251 Validation Accuracy: 0.464200\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:  1510.5947 Validation Accuracy: 0.480600\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss:  1297.1625 Validation Accuracy: 0.475400\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss:  1124.0696 Validation Accuracy: 0.467200\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss:  1676.5614 Validation Accuracy: 0.454400\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss:  1268.4680 Validation Accuracy: 0.463200\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:  1474.6454 Validation Accuracy: 0.478200\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss:  1205.9288 Validation Accuracy: 0.477200\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss:  1054.2303 Validation Accuracy: 0.469800\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss:  1711.8828 Validation Accuracy: 0.449800\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss:  1098.7411 Validation Accuracy: 0.469000\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:  1511.5358 Validation Accuracy: 0.474400\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss:  1099.0166 Validation Accuracy: 0.474800\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss:   892.8550 Validation Accuracy: 0.473200\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss:  1567.9176 Validation Accuracy: 0.450200\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss:  1086.7092 Validation Accuracy: 0.470200\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:  1454.3218 Validation Accuracy: 0.476400\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss:  1036.5398 Validation Accuracy: 0.472200\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss:   853.0114 Validation Accuracy: 0.476400\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss:  1384.4048 Validation Accuracy: 0.452200\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss:   917.5477 Validation Accuracy: 0.474800\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:  1336.1031 Validation Accuracy: 0.476600\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss:  1041.2544 Validation Accuracy: 0.474200\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss:   854.2043 Validation Accuracy: 0.473400\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss:  1253.5552 Validation Accuracy: 0.454800\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss:   863.9514 Validation Accuracy: 0.474200\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:  1181.9133 Validation Accuracy: 0.480600\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss:  1103.3916 Validation Accuracy: 0.478000\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss:   753.1221 Validation Accuracy: 0.474000\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss:  1227.2797 Validation Accuracy: 0.456800\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss:   754.5188 Validation Accuracy: 0.473400\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:  1076.0016 Validation Accuracy: 0.483200\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss:   968.7737 Validation Accuracy: 0.476600\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss:   840.6724 Validation Accuracy: 0.471400\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss:  1084.1370 Validation Accuracy: 0.454000\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss:   734.7033 Validation Accuracy: 0.469000\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:   983.6136 Validation Accuracy: 0.484000\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss:   935.8106 Validation Accuracy: 0.478200\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss:   753.7666 Validation Accuracy: 0.475600\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss:  1078.8673 Validation Accuracy: 0.456000\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss:   738.5055 Validation Accuracy: 0.462000\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:   846.1724 Validation Accuracy: 0.478600\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss:   934.5189 Validation Accuracy: 0.479400\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss:   781.0665 Validation Accuracy: 0.476000\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss:  1019.2836 Validation Accuracy: 0.452600\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss:   764.6469 Validation Accuracy: 0.458800\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:   891.7469 Validation Accuracy: 0.476400\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss:   718.0105 Validation Accuracy: 0.478000\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss:   797.7256 Validation Accuracy: 0.474800\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss:  1014.6769 Validation Accuracy: 0.453200\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss:   644.3475 Validation Accuracy: 0.460800\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:   855.1941 Validation Accuracy: 0.472400\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss:   617.7744 Validation Accuracy: 0.482600\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss:   649.0353 Validation Accuracy: 0.481600\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss:  1007.8597 Validation Accuracy: 0.456000\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss:   550.4788 Validation Accuracy: 0.476400\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:   768.8129 Validation Accuracy: 0.470800\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss:   690.5823 Validation Accuracy: 0.474600\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss:   600.5688 Validation Accuracy: 0.475000\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss:   901.4525 Validation Accuracy: 0.464000\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss:   487.7376 Validation Accuracy: 0.476400\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:   697.4969 Validation Accuracy: 0.475400\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss:   695.5640 Validation Accuracy: 0.472000\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss:   587.3153 Validation Accuracy: 0.465800\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss:   840.1493 Validation Accuracy: 0.460800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65, CIFAR-10 Batch 5:  Loss:   406.5063 Validation Accuracy: 0.475600\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:   621.1398 Validation Accuracy: 0.481200\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss:   629.0857 Validation Accuracy: 0.473400\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss:   549.5690 Validation Accuracy: 0.468000\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss:   760.8097 Validation Accuracy: 0.463000\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss:   423.8147 Validation Accuracy: 0.474800\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:   592.0054 Validation Accuracy: 0.483000\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss:   569.9562 Validation Accuracy: 0.479400\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss:   482.5422 Validation Accuracy: 0.471400\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss:   795.4749 Validation Accuracy: 0.456200\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss:   470.1076 Validation Accuracy: 0.476600\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:   602.8627 Validation Accuracy: 0.473400\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss:   553.5216 Validation Accuracy: 0.476600\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss:   519.8168 Validation Accuracy: 0.470600\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss:   715.4275 Validation Accuracy: 0.455200\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss:   432.4627 Validation Accuracy: 0.471600\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:   628.2228 Validation Accuracy: 0.474800\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss:   639.2594 Validation Accuracy: 0.476400\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss:   422.4926 Validation Accuracy: 0.475800\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss:   711.1508 Validation Accuracy: 0.465600\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss:   483.9655 Validation Accuracy: 0.464400\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:   623.7140 Validation Accuracy: 0.474400\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss:   693.7676 Validation Accuracy: 0.465000\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss:   459.0101 Validation Accuracy: 0.482000\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss:   684.4047 Validation Accuracy: 0.467400\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss:   452.8123 Validation Accuracy: 0.469800\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:   619.6340 Validation Accuracy: 0.479600\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss:   710.9008 Validation Accuracy: 0.467000\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss:   558.9893 Validation Accuracy: 0.481600\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss:   679.9125 Validation Accuracy: 0.469400\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss:   377.6767 Validation Accuracy: 0.478400\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:   586.2552 Validation Accuracy: 0.484000\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss:   513.4193 Validation Accuracy: 0.476800\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss:   516.8602 Validation Accuracy: 0.474400\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss:   589.6516 Validation Accuracy: 0.473800\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss:   409.9846 Validation Accuracy: 0.487800\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:   522.1141 Validation Accuracy: 0.491800\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss:   438.4998 Validation Accuracy: 0.473200\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss:   598.4540 Validation Accuracy: 0.469000\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss:   606.2216 Validation Accuracy: 0.479000\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss:   465.6224 Validation Accuracy: 0.479200\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:   573.7599 Validation Accuracy: 0.489800\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss:   365.8491 Validation Accuracy: 0.483800\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss:   518.1311 Validation Accuracy: 0.470800\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss:   731.0240 Validation Accuracy: 0.482000\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss:   432.1927 Validation Accuracy: 0.481600\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:   556.0533 Validation Accuracy: 0.483800\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss:   633.7148 Validation Accuracy: 0.486000\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss:   583.2684 Validation Accuracy: 0.466000\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss:   749.5426 Validation Accuracy: 0.478400\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss:   393.3063 Validation Accuracy: 0.481200\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:   565.9695 Validation Accuracy: 0.484400\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss:   737.1904 Validation Accuracy: 0.483200\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss:   365.1733 Validation Accuracy: 0.478400\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss:   662.3732 Validation Accuracy: 0.480200\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss:   320.2857 Validation Accuracy: 0.486800\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:   495.7242 Validation Accuracy: 0.482200\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss:   535.7327 Validation Accuracy: 0.485600\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss:   262.7642 Validation Accuracy: 0.491400\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss:   645.6536 Validation Accuracy: 0.478600\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss:   313.0448 Validation Accuracy: 0.487400\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:   425.9492 Validation Accuracy: 0.484400\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss:   448.5247 Validation Accuracy: 0.488000\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss:   271.8456 Validation Accuracy: 0.491800\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss:   558.0535 Validation Accuracy: 0.487400\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss:   262.2612 Validation Accuracy: 0.487400\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:   428.8815 Validation Accuracy: 0.480000\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss:   423.0405 Validation Accuracy: 0.487600\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss:   289.0367 Validation Accuracy: 0.489400\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss:   531.1926 Validation Accuracy: 0.488600\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss:   186.9893 Validation Accuracy: 0.498200\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:   518.1011 Validation Accuracy: 0.479200\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss:   377.8032 Validation Accuracy: 0.481800\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss:   278.9493 Validation Accuracy: 0.489200\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss:   508.0957 Validation Accuracy: 0.489400\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss:   177.0929 Validation Accuracy: 0.498400\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:   444.4543 Validation Accuracy: 0.477200\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss:   333.6676 Validation Accuracy: 0.482200\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss:   233.9981 Validation Accuracy: 0.488400\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss:   451.5894 Validation Accuracy: 0.486400\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss:   185.7437 Validation Accuracy: 0.499600\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:   355.4937 Validation Accuracy: 0.475600\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss:   351.6028 Validation Accuracy: 0.481600\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss:   293.2746 Validation Accuracy: 0.488400\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss:   405.2815 Validation Accuracy: 0.482000\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss:   178.4854 Validation Accuracy: 0.503800\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:   327.8770 Validation Accuracy: 0.477400\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss:   336.1634 Validation Accuracy: 0.485600\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss:   247.9351 Validation Accuracy: 0.492800\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss:   447.8037 Validation Accuracy: 0.476800\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss:   200.7239 Validation Accuracy: 0.498400\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:   362.3195 Validation Accuracy: 0.480600\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss:   334.9407 Validation Accuracy: 0.484400\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss:   263.8139 Validation Accuracy: 0.491800\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss:   457.9420 Validation Accuracy: 0.473000\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss:   224.4427 Validation Accuracy: 0.489200\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:   397.1065 Validation Accuracy: 0.482000\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss:   252.1039 Validation Accuracy: 0.483000\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss:   262.4093 Validation Accuracy: 0.489800\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss:   414.2277 Validation Accuracy: 0.472200\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss:   219.3482 Validation Accuracy: 0.491200\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:   329.3936 Validation Accuracy: 0.488400\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss:   258.8225 Validation Accuracy: 0.491600\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss:   250.6446 Validation Accuracy: 0.485800\n",
      "Epoch 86, CIFAR-10 Batch 4:  Loss:   374.6221 Validation Accuracy: 0.478600\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss:   196.1005 Validation Accuracy: 0.494600\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:   306.7029 Validation Accuracy: 0.485200\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss:   334.7659 Validation Accuracy: 0.493000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87, CIFAR-10 Batch 3:  Loss:   289.1199 Validation Accuracy: 0.490800\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss:   334.3268 Validation Accuracy: 0.478400\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss:   125.9184 Validation Accuracy: 0.495000\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:   248.9417 Validation Accuracy: 0.490200\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss:   265.7910 Validation Accuracy: 0.492800\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss:   172.8716 Validation Accuracy: 0.494000\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss:   411.4049 Validation Accuracy: 0.479800\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss:   108.7863 Validation Accuracy: 0.492200\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:   221.1270 Validation Accuracy: 0.488800\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss:   282.3089 Validation Accuracy: 0.493200\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss:   139.0757 Validation Accuracy: 0.488600\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss:   473.5409 Validation Accuracy: 0.477200\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss:   113.7125 Validation Accuracy: 0.488200\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:   198.2244 Validation Accuracy: 0.487600\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss:   280.8954 Validation Accuracy: 0.495400\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss:   174.0351 Validation Accuracy: 0.486600\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss:   361.6785 Validation Accuracy: 0.483000\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss:   136.8137 Validation Accuracy: 0.492600\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:   220.9012 Validation Accuracy: 0.490400\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss:   284.5341 Validation Accuracy: 0.491400\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss:   188.7149 Validation Accuracy: 0.490000\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss:   264.4645 Validation Accuracy: 0.487400\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss:   141.5933 Validation Accuracy: 0.495200\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:   192.2498 Validation Accuracy: 0.492000\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss:   283.0604 Validation Accuracy: 0.488400\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss:   255.3046 Validation Accuracy: 0.488200\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss:   275.6157 Validation Accuracy: 0.484200\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss:   158.2325 Validation Accuracy: 0.496000\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:   195.8453 Validation Accuracy: 0.490000\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss:   231.8501 Validation Accuracy: 0.491400\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss:   206.3093 Validation Accuracy: 0.496800\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss:   256.3910 Validation Accuracy: 0.484600\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss:   161.5944 Validation Accuracy: 0.492800\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:   226.9759 Validation Accuracy: 0.494400\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss:   190.7918 Validation Accuracy: 0.486200\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss:   181.0598 Validation Accuracy: 0.496600\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss:   214.0098 Validation Accuracy: 0.480000\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss:   187.5075 Validation Accuracy: 0.497600\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:   191.6222 Validation Accuracy: 0.490600\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss:   188.1007 Validation Accuracy: 0.485200\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss:   160.6708 Validation Accuracy: 0.494600\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss:   196.6812 Validation Accuracy: 0.479400\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss:   262.9359 Validation Accuracy: 0.488000\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:   177.5396 Validation Accuracy: 0.498800\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss:   248.0481 Validation Accuracy: 0.489600\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss:   137.7904 Validation Accuracy: 0.496000\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss:   189.8008 Validation Accuracy: 0.477200\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss:   195.3861 Validation Accuracy: 0.491200\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:   243.4417 Validation Accuracy: 0.499400\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss:   182.9714 Validation Accuracy: 0.491800\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss:   124.5416 Validation Accuracy: 0.489000\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss:   232.0396 Validation Accuracy: 0.474400\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss:   199.9337 Validation Accuracy: 0.491800\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:   297.9695 Validation Accuracy: 0.493600\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss:   168.5109 Validation Accuracy: 0.490200\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss:   112.5283 Validation Accuracy: 0.491800\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss:   264.5414 Validation Accuracy: 0.471000\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss:   144.1980 Validation Accuracy: 0.489800\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:   237.0877 Validation Accuracy: 0.491600\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss:   179.4392 Validation Accuracy: 0.488600\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss:    77.9190 Validation Accuracy: 0.497800\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss:   211.1824 Validation Accuracy: 0.476800\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss:   162.5303 Validation Accuracy: 0.484200\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:   196.0972 Validation Accuracy: 0.495800\n",
      "Epoch 100, CIFAR-10 Batch 2:  Loss:   177.7386 Validation Accuracy: 0.486600\n",
      "Epoch 100, CIFAR-10 Batch 3:  Loss:    90.7519 Validation Accuracy: 0.494200\n",
      "Epoch 100, CIFAR-10 Batch 4:  Loss:   179.8866 Validation Accuracy: 0.481000\n",
      "Epoch 100, CIFAR-10 Batch 5:  Loss:   135.9916 Validation Accuracy: 0.488200\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.4913200825452805\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArsAAAJ/CAYAAAB4GhsgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndkVERESksP5/pgaVgXQ1HpYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f06280d3b38>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 349
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
